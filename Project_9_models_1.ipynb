{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Models. https://gist.github.com/ElmanSafarov1960/2f6a1933d43b17e3795964ea04c89271"
      ],
      "metadata": {
        "id": "Me7mgcTbhyOK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LqjdS3Qhc_V"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns=['churn', 'id'])\n",
        "y = df['churn']\n",
        "\n",
        "# Проверка бесконечностей\n",
        "X = X.replace([np.inf, -np.inf], np.nan)\n",
        "X = X.fillna(X.median())\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Перевірка результату\n",
        "\n",
        "print(\"\\n***Розміри наборів:***\")\n",
        "print(\"X_train:\", X_train.shape)\n",
        "print(\"X_test:\", X_test.shape)\n",
        "print(\"y_train:\", y_train.shape)\n",
        "print(\"y_test:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "***Розміри наборів:***\n",
        "X_train: (57819, 10)\n",
        "X_test: (14455, 10)\n",
        "y_train: (57819,)\n",
        "y_test: (14455,)\n"
      ],
      "metadata": {
        "id": "bBPiOKHbi1ok"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Models. 3.1. Вибір та ініціалізація алгоритмів машинного навчання. Для розв’язання задачі прогнозування відтоку клієнтів телекомунікаційної компанії було обрано декілька алгоритмів машинного навчання, які належать до різних класів моделей. Такий підхід дозволяє провести порівняльний аналіз їх ефективності та обрати найбільш придатну модель для практичного застосування. У межах дослідження використано логістичну регресію, Random Forest, Gradient Boosting та штучну нейронну мережу типу Multilayer Perceptron (MLP). Логістична регресія застосовується як базова лінійна модель завдяки простоті реалізації та високій інтерпретованості результатів. Random Forest та Gradient Boosting належать до ансамблевих методів і дозволяють ефективно моделювати нелінійні залежності між ознаками. Нейронна мережа MLP була використана як додаткова модель для аналізу складних нелінійних взаємозв’язків між характеристиками клієнтів."
      ],
      "metadata": {
        "id": "45GZkglMh9Jb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(\n",
        "        max_iter=1000,\n",
        "        class_weight=\"balanced\",\n",
        "        random_state=42\n",
        "    ),\n",
        "\n",
        "    \"Random Forest\": RandomForestClassifier(\n",
        "        n_estimators=200,\n",
        "        random_state=42,\n",
        "        class_weight=\"balanced\"\n",
        "    ),\n",
        "\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(\n",
        "        random_state=42\n",
        "    ),\n",
        "\n",
        "    \"Neural Network (MLP)\": MLPClassifier(\n",
        "        hidden_layer_sizes=(64, 32),\n",
        "        activation='relu',\n",
        "        solver='adam',\n",
        "        alpha=0.001,\n",
        "        max_iter=500,\n",
        "        random_state=42\n",
        "    )\n",
        "}"
      ],
      "metadata": {
        "id": "mh-FELGZh-lR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2. Базове навчання та первинна оцінка моделей Перед навчанням моделей набір даних було поділено на тренувальну та тестову вибірки у співвідношенні 80% до 20% із застосуванням стратифікації за цільовою змінною, що забезпечує збереження пропорцій класів. Числові ознаки були стандартизовані з використанням методу StandardScaler, що є обов’язковим для коректної роботи логістичної регресії та нейронної мережі. Базове навчання кожної моделі проводилося на тренувальному наборі даних, після чого здійснювалася оцінка якості класифікації за метрикою Accuracy на тестовому наборі. Отримані результати показали, що ансамблеві методи та нейронна мережа демонструють вищу якість прогнозування порівняно з лінійною моделлю."
      ],
      "metadata": {
        "id": "7uTezBm9iH9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    results[name] = accuracy_score(y_test, y_pred)\n",
        "    print(f\"{name} Accuracy: {results[name]:.4f}\")"
      ],
      "metadata": {
        "id": "IAFXh2BriJuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression Accuracy: 0.8785\n",
        "Random Forest Accuracy: 0.9404\n",
        "Gradient Boosting Accuracy: 0.9373\n",
        "Neural Network (MLP) Accuracy: 0.9333\n"
      ],
      "metadata": {
        "id": "KiTdLqSujCnl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 3.3. Крос-валідація та підбір гіперпараметрів. З метою підвищення якості прогнозування було виконано підбір оптимальних гіперпараметрів для моделі Random Forest з використанням методу Grid Search у поєднанні з п’ятикратною крос-валідацією. Такий підхід дозволяє зменшити ризик перенавчання та отримати більш стабільну оцінку ефективності моделі. Як основну метрику оптимізації було обрано F1-score, оскільки вона враховує баланс між точністю та повнотою класифікації, що є особливо важливим для задачі прогнозування відтоку клієнтів. Нейронна мережа MLP використовувалася без додаткового підбору гіперпараметрів та слугувала порівняльною моделлю. GridSearch выполняется для лучшей ансамблевой модели — Random Forest\n",
        " 3.4. Фінальна оцінка якості моделі Фінальна оцінка якості була проведена для моделі Random Forest з оптимальними гіперпараметрами на незалежному тестовому наборі даних. Для комплексного аналізу ефективності використано такі метрики, як Accuracy, Precision, Recall та F1-score. Застосування кількох метрик дозволяє більш повно оцінити здатність моделі правильно ідентифікувати клієнтів, схильних до відтоку, та мінімізувати кількість помилкових прогнозів. Отримані результати підтверджують доцільність використання ансамблевих методів для вирішення даної задачі."
      ],
      "metadata": {
        "id": "cB94H837iSnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    \"n_estimators\": [100, 200],\n",
        "    \"max_depth\": [None, 5, 10],\n",
        "    \"min_samples_split\": [2, 5]\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier(\n",
        "    random_state=42,\n",
        "    class_weight=\"balanced\"\n",
        ")\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=rf,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring=\"f1\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "\n",
        "best_model = grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "YTiV2-JSiUAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n"
      ],
      "metadata": {
        "id": "AGka37FgjIQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_final = best_model.predict(X_test)\n",
        "\n",
        "print(\"Final model metrics:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_final))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred_final))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred_final))\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred_final))\n",
        "\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred_final))"
      ],
      "metadata": {
        "id": "0OSGbyxoidqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final model metrics:\n",
        "Accuracy: 0.9406433759944656\n",
        "Precision: 0.9571720787522373\n",
        "Recall: 0.9347066167290886\n",
        "F1-score: 0.9458059626073775\n",
        "\n",
        "Classification Report:\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.92      0.95      0.93      6445\n",
        "           1       0.96      0.93      0.95      8010\n",
        "\n",
        "    accuracy                           0.94     14455\n",
        "   macro avg       0.94      0.94      0.94     14455\n",
        "weighted avg       0.94      0.94      0.94     14455\n",
        "\n"
      ],
      "metadata": {
        "id": "hlTedTlqjOCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "auc = roc_auc_score(y_test, y_proba)\n",
        "print(\"ROC AUC:\", auc)\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "\n",
        "plt.plot(fpr, tpr)\n",
        "plt.plot([0,1],[0,1],'--')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5g0xQFnnijrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ROC AUC: 0.980840251082578\n"
      ],
      "metadata": {
        "id": "C1hetQmjjY-O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.5. Аналіз важливості ознак Заключним етапом дослідження став аналіз важливості ознак для фінальної моделі Random Forest. Для цього було використано вбудований механізм оцінки важливості ознак, який дозволяє визначити внесок кожної характеристики у процес прийняття рішення моделлю. Результати аналізу були візуалізовані у вигляді стовпчикової діаграми, що надало можливість виділити найбільш значущі фактори впливу на відтік клієнтів. Отримана інформація може бути використана для формування бізнес-рішень, спрямованих на підвищення рівня утримання клієнтів."
      ],
      "metadata": {
        "id": "_mtdySTMiohy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importance = pd.Series(\n",
        "    best_model.feature_importances_,\n",
        "    index=X.columns\n",
        ").sort_values(ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "feature_importance.head(10).plot(kind=\"bar\")\n",
        "plt.title(\"Feature Importance (Random Forest)\")\n",
        "plt.ylabel(\"Importance\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TVrkqXmXitEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3E3p6STLjfHZ"
      }
    }
  ]
}